{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width = 400, align = \"center\"></a>\n",
    "\n",
    "# <center>Hierarchical Clustering</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido a Lab of Hierarchical Clustering with Python usando el paquete Scipy y Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Hierarchical Clustering - Agglomerative\n",
    "\n",
    "Vamos a ver una técnica de agrupación, que es <b> Aglomerative Hierarchical Clustering </b>. Recuerde que la aglomeración es el enfoque de abajo hacia arriba. <br> <br>\n",
    "En este laboratorio, analizaremos el agrupamiento aglomerativo, que es más popular que el agrupamiento divisivo. <br> <br>\n",
    "También usaremos Enlace completo como Criterios de enlace. <br>\n",
    "<b> <i> NOTA: ¡También puede intentar usar el enlace promedio donde quiera que se use el enlace completo para ver la diferencia! </i> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy import ndimage \n",
    "from scipy.cluster import hierarchy \n",
    "from scipy.spatial import distance_matrix \n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn import manifold, datasets \n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "from sklearn.datasets.samples_generator import make_blobs \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Generating Random Data // Generando datos aleatorios\n",
    "Generaremos un conjunto de datos utilizando la clase <b> make_blobs </b>. <br> <br>\n",
    "Ingrese estos parámetros en make_blobs:\n",
    "<ul>\n",
    "    <li> <b>n_samples</b>: El número total de puntos divididos equitativamente entre grupos. </li>\n",
    "    <ul> <li> Elige un número de 10-1500 </li> </ul>\n",
    "    <li> <b>centers</b>: El número de centros para generar, o las ubicaciones de centros fijos. </li>\n",
    "    <ul> <li> Elija matrices de coordenadas x, y para generar los centros. Tener 1-10 centros (ej. Centros = [[1,1], [2,5]]) </li> </ul>\n",
    "    <li> <b>cluster_std</b>: La desviación estándar de los grupos. Cuanto mayor es el número, más separados están los grupos</li>\n",
    "    <ul> <li> Escoge un número entre 0.5-1.5 </li> </ul>\n",
    "</ul> <br>\n",
    "Save the result to <b>X1</b> and <b>y1</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1, y1 = make_blobs(n_samples=50, centers=[[4,4], [-2, -1], [1, 1], [10,4]], cluster_std=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the scatter plot of the randomly generated data // **Trace el diagrama de dispersión de los datos generados aleatoriamente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X1[:, 0], X1[:, 1], marker='o') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Agglomerative Clustering // Agrupamiento Aglomerativo\n",
    "Comenzaremos agrupando los puntos de datos aleatorios que acabamos de crear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b> Agglomerative Clustering </b> La clase requerirá dos entradas:\n",
    "<ul>\n",
    "    <li> <b>n_clusters</b>: El número de grupos para formar, así como el número de centroides para generar. </li>\n",
    "    <ul> <li> El valor será: 4 </li> </ul>\n",
    "    <li> <b>linkage</b>: Qué criterio de vinculación utilizar. El criterio de vinculación determina qué distancia usar entre conjuntos de observación. El algoritmo fusionará los pares de clúster que minimizan este criterio. </li>\n",
    "    <ul> \n",
    "        <li> El valor será: 'completo' </li> \n",
    "        <li> <b>Note</b>: Se recomienda que pruebe todo con 'average' también </li>\n",
    "    </ul>\n",
    "</ul> <br>\n",
    "Guarde el resultado en una variable llamada <b> agglom </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agglom = AgglomerativeClustering(n_clusters = 4, linkage = 'average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste el modelo con <b> X2 </b> y <b> y2 </b> de los datos generados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agglom.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ejecute el siguiente código para mostrar el agrupamiento! <br>\n",
    "Recuerde leer el código y los comentarios para comprender mejor cómo funciona el trazado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure of size 6 inches by 4 inches.\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "# These two lines of code are used to scale the data points down,\n",
    "# Or else the data points will be scattered very far apart.\n",
    "\n",
    "# Create a minimum and maximum range of X1.\n",
    "x_min, x_max = np.min(X1, axis=0), np.max(X1, axis=0)\n",
    "\n",
    "# Get the average distance for X1.\n",
    "X1 = (X1 - x_min) / (x_max - x_min)\n",
    "\n",
    "# This loop displays all of the datapoints.\n",
    "for i in range(X1.shape[0]):\n",
    "    # Replace the data points with their respective cluster value \n",
    "    # (ex. 0) and is color coded with a colormap (plt.cm.spectral)\n",
    "    plt.text(X1[i, 0], X1[i, 1], str(y1[i]),\n",
    "             color=plt.cm.nipy_spectral(agglom.labels_[i] / 10.),\n",
    "             fontdict={'weight': 'bold', 'size': 9})\n",
    "    \n",
    "# Remove the x ticks, y ticks, x and y axis\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "#plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "# Display the plot of the original data before clustering\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker='.')\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dendrogram Associated for the Agglomerative Hierarchical Clustering // Dendrograma asociado a la agrupación jerárquica aglomerativa\n",
    "Recuerde que una <b> matriz de distancia </b> contiene la <b> distancia desde cada punto a cualquier otro punto de un conjunto de datos </b>. <br>\n",
    "Use la función <b> distancia_matriz, </b> que requiere <b> dos entradas </b>. Utilice la matriz de características, <b> X2 </b> como ambas entradas y guarde la matriz de distancia en una variable llamada <b> dist_matrix </b> <br> <br>\n",
    "Recuerde que los valores de distancia son simétricos, con una diagonal de 0. Esta es una forma de asegurarse de que su matriz sea correcta. <br> (imprima dist_matrix para asegurarse de que sea correcto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist_matrix = distance_matrix(X1,X1) \n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la clase <b> enlace </b> de la jerarquía, pase los parámetros:\n",
    "<ul>\n",
    "    <li> La matriz de distancia </li>\n",
    "    <li> 'completo' para un enlace completo</li>\n",
    "</ul> <br>\n",
    "Guarde el resultado en una variable llamada <b> Z </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = hierarchy.linkage(dist_matrix, 'complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hierarchical clustering** generalmente se visualiza como un dendrograma como se muestra en la siguiente celda. Cada fusión está representada por una línea horizontal. La coordenada y de la línea horizontal es la similitud de los dos grupos que se fusionaron, donde las ciudades se ven como grupos únicos.\n",
    "Al pasar de la capa inferior al nodo superior, un dendrograma nos permite reconstruir el historial de fusiones que dieron como resultado la agrupación representada.\n",
    "\n",
    "A continuación, guardaremos el dendrograma en una variable llamada <b> dendro </b>. Al hacer esto, también se mostrará el dendrograma.\n",
    "Usando la clase <b> dendrograma </b> de la jerarquía, pase el parámetro:\n",
    "<ul> <li> Z </li> </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendro = hierarchy.dendrogram(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "Si usó el enlace __complete__ para su caso, cámbielo a enlace __average__ para ver cómo cambia el dendograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click __here__ for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "    \n",
    "Z = hierarchy.linkage(dist_matrix, 'average')\n",
    "dendro = hierarchy.dendrogram(Z)\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Clustering on Vehicle dataset\n",
    "\n",
    "Imagine que un fabricante de automóviles ha desarrollado prototipos para un nuevo vehículo. Antes de introducir el nuevo modelo en su gama, el fabricante desea determinar qué vehículos existentes en el mercado se parecen más a los prototipos, es decir, cómo se pueden agrupar los vehículos, qué grupo es el más similar al modelo y, por lo tanto, qué modelos estarán compitiendo contra.\n",
    "\n",
    "Nuestro objetivo aquí es utilizar métodos de agrupamiento para encontrar los grupos de vehículos más distintivos. Resumirá los vehículos existentes y ayudará a la fabricación a tomar decisiones sobre nuevos modelos de manera simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "Para descargar los datos, usaremos **`!wget`**. Para descargar los datos, usaremos `!wget` to download it from IBM Object Storage.  \n",
    "__Did you know?__ When it comes to Machine Learning, you will likely be working with large datasets. As a business, where can you host your data? IBM is offering a unique opportunity for businesses, with 10 Tb of IBM Cloud Object Storage: [Sign up now for free](http://cocl.us/ML0101EN-IBM-Offer-CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O cars_clus.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cars_clus.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data // Leer datos\n",
    "leamos el conjunto de datos para ver qué características ha recopilado el fabricante sobre los modelos existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'cars_clus.csv'\n",
    "\n",
    "#Read csv\n",
    "pdf = pd.read_csv(filename)\n",
    "print (\"Shape of dataset: \", pdf.shape)\n",
    "\n",
    "pdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los conjuntos de características incluyen price in thousands (price), engine size (engine_s), horsepower (horsepow), wheelbase (wheelbas), width (width), length (length), curb weight (curb_wgt), fuel capacity (fuel_cap) and fuel efficiency (mpg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning // Limpieza de datos\n",
    "simplemente borremos el conjunto de datos soltando las filas que tienen un valor nulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of dataset before cleaning: \", pdf.size)\n",
    "pdf[[ 'sales', 'resale', 'type', 'price', 'engine_s',\n",
    "       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',\n",
    "       'mpg', 'lnsales']] = pdf[['sales', 'resale', 'type', 'price', 'engine_s',\n",
    "       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',\n",
    "       'mpg', 'lnsales']].apply(pd.to_numeric, errors='coerce')\n",
    "pdf = pdf.dropna()\n",
    "pdf = pdf.reset_index(drop=True)\n",
    "print (\"Shape of dataset after cleaning: \", pdf.size)\n",
    "pdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "Seleccionemos nuestro conjunto de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = pdf[['engine_s',  'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Ahora podemos normalizar el conjunto de características. __MinMaxScaler__ transforma características al escalar cada característica a un rango determinado. Es por defecto (0, 1). Es decir, este estimador escala y traduce cada característica individualmente de modo que esté entre cero y uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x = featureset.values #returns a numpy array\n",
    "min_max_scaler = MinMaxScaler()\n",
    "feature_mtx = min_max_scaler.fit_transform(x)\n",
    "feature_mtx [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering using Scipy\n",
    "En esta parte usamos el paquete Scipy para agrupar el conjunto de datos:\n",
    "Primero, calculamos la matriz de distancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "leng = feature_mtx.shape[0]\n",
    "D = scipy.zeros([leng,leng])\n",
    "for i in range(leng):\n",
    "    for j in range(leng):\n",
    "        D[i,j] = scipy.spatial.distance.euclidean(feature_mtx[i], feature_mtx[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In agglomerative clustering, en cada iteración, el algoritmo debe actualizar la matriz de distancia para reflejar la distancia del grupo recién formado con los grupos restantes en el bosque.\n",
    "Los siguientes métodos son compatibles con Scipy para calcular la distancia entre el grupo recién formado y cada uno:\n",
    "    - single\n",
    "    - complete\n",
    "    - average\n",
    "    - weighted\n",
    "    - centroid\n",
    "    \n",
    "    \n",
    "Utilizamos __complete__ para nuestro caso, pero no dude en cambiarlo para ver cómo cambian los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import scipy.cluster.hierarchy\n",
    "Z = hierarchy.linkage(D, 'complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esencialmente, Hierarchical clustering no requiere un número predeterminado de clústeres. Sin embargo, en algunas aplicaciones queremos una partición de clústeres disjuntos como en clustering plano.\n",
    "Para que pueda usar una línea de corte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "max_d = 3\n",
    "clusters = fcluster(Z, max_d, criterion='distance')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, puede determinar el número de clústeres directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "k = 5\n",
    "clusters = fcluster(Z, k, criterion='maxclust')\n",
    "clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the dendrogram: // Ahora, grafica el dendrograma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pylab.figure(figsize=(18,50))\n",
    "def llf(id):\n",
    "    return '[%s %s %s]' % (pdf['manufact'][id], pdf['model'][id], int(float(pdf['type'][id])) )\n",
    "    \n",
    "dendro = hierarchy.dendrogram(Z,  leaf_label_func=llf, leaf_rotation=0, leaf_font_size =12, orientation = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering using scikit-learn\n",
    "Vamos a hacerlo de nuevo, pero esta vez usando el paquete scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = distance_matrix(feature_mtx,feature_mtx) \n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos usar la función 'AgglomerativeClustering' de la biblioteca scikit-learn para agrupar el conjunto de datos. AgglomerativeClustering realiza una **hierarchical clustering**(agrupación jerárquica) utilizando un enfoque ascendente. Los criterios de vinculación determinan la métrica utilizada para la estrategia de fusión:\n",
    "\n",
    "- Ward minimiza la suma de las diferencias al cuadrado dentro de todos los grupos. Es un enfoque que minimiza la varianza y, en este sentido, es similar a la función objetivo k-means pero se aborda con un enfoque jerárquico aglomerativo.\n",
    "- Maximum or complete linkage minimizes the maximum distance between observaciones de pares de grupos.\n",
    "- Average linkage minimizes the average of the distances between all observaciones de pares de grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglom = AgglomerativeClustering(n_clusters = 6, linkage = 'complete')\n",
    "agglom.fit(feature_mtx)\n",
    "agglom.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos agregar un nuevo campo a nuestro marco de datos para mostrar el grupo de cada fila:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['cluster_'] = agglom.labels_\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "n_clusters = max(agglom.labels_)+1\n",
    "colors = cm.rainbow(np.linspace(0, 1, n_clusters))\n",
    "cluster_labels = list(range(0, n_clusters))\n",
    "\n",
    "# Create a figure of size 6 inches by 4 inches.\n",
    "plt.figure(figsize=(16,14))\n",
    "\n",
    "for color, label in zip(colors, cluster_labels):\n",
    "    subset = pdf[pdf.cluster_ == label]\n",
    "    for i in subset.index:\n",
    "            plt.text(subset.horsepow[i], subset.mpg[i],str(subset['model'][i]), rotation=25) \n",
    "    plt.scatter(subset.horsepow, subset.mpg, s= subset.price*10, c=color, label='cluster'+str(label),alpha=0.5)\n",
    "#    plt.scatter(subset.horsepow, subset.mpg)\n",
    "plt.legend()\n",
    "plt.title('Clusters')\n",
    "plt.xlabel('horsepow')\n",
    "plt.ylabel('mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede ver, estamos viendo la distribución de cada grupo utilizando el diagrama de dispersión, pero no está muy claro dónde está el centroide de cada grupo. Además, hay 2 tipos de vehículos en nuestro conjunto de datos, \"camión\" (valor de 1 en la columna de tipo) y \"automóvil\" (valor de 1 en la columna de tipo). Entonces, los usamos para distinguir las clases y resumir el clúster. Primero contamos el número de casos en cada grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.groupby(['cluster_','type'])['cluster_'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos ver las características de cada grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cars = pdf.groupby(['cluster_','type'])['horsepow','engine_s','mpg','price'].mean()\n",
    "agg_cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Es obvio que tenemos 3 grupos principales con la mayoría de los vehículos en esos.\n",
    "\n",
    "__Cars__:\n",
    "- Cluster 1: with almost high mpg, and low in horsepower.\n",
    "- Cluster 2: with good mpg and horsepower, but higher price than average.\n",
    "- Cluster 3: with low mpg, high horsepower, highest price.\n",
    "    \n",
    "    \n",
    "    \n",
    "__Trucks__:\n",
    "- Cluster 1: with almost highest mpg among trucks, and lowest in horsepower and price.\n",
    "- Cluster 2: with almost low mpg and medium horsepower, but higher price than average.\n",
    "- Cluster 3: with good mpg and horsepower, low price.\n",
    "\n",
    "Tenga en cuenta que no utilizamos __type__ , y __price__ de los automóviles en el proceso de agrupación, pero la agrupación jerárquica podría forjar los grupos y discriminarlos con una precisión bastante alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "for color, label in zip(colors, cluster_labels):\n",
    "    subset = agg_cars.loc[(label,),]\n",
    "    for i in subset.index:\n",
    "        plt.text(subset.loc[i][0]+5, subset.loc[i][2], 'type='+str(int(i)) + ', price='+str(int(subset.loc[i][3]))+'k')\n",
    "    plt.scatter(subset.horsepow, subset.mpg, s=subset.price*20, c=color, label='cluster'+str(label))\n",
    "plt.legend()\n",
    "plt.title('Clusters')\n",
    "plt.xlabel('horsepow')\n",
    "plt.ylabel('mpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?\n",
    "\n",
    "IBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems – by your enterprise as a whole. A free trial is available through this course, available here: [SPSS Modeler](http://cocl.us/ML0101EN-SPSSModeler).\n",
    "\n",
    "Also, you can use Watson Studio to run these notebooks faster with bigger datasets. Watson Studio is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, Watson Studio enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of Watson Studio users today with a free account at [Watson Studio](https://cocl.us/ML0101EN_DSX)\n",
    "\n",
    "### Thanks for completing this lesson!\n",
    "\n",
    "Notebook created by: <a href = \"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>\n",
    "\n",
    "<hr>\n",
    "Copyright &copy; 2018 [Cognitive Class](https://cocl.us/DX0108EN_CC). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
